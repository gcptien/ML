{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 53072 entries, 0 to 53071\n",
      "Data columns (total 4 columns):\n",
      "name         52982 non-null object\n",
      "review       52831 non-null object\n",
      "rating       53072 non-null float64\n",
      "sentiment    53072 non-null int64\n",
      "dtypes: float64(1), int64(1), object(2)\n",
      "memory usage: 1.6+ MB\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import math\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "%matplotlib inline\n",
    "\n",
    "products = pd.read_csv('amazon_baby_subset.csv',dtype={'name': str, 'review': str, 'rating': float})\n",
    "products.tail(10)\n",
    "products.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 1    26579\n",
       "-1    26493\n",
       "Name: sentiment, dtype: int64"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "products['sentiment'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "193"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "with open('important_words.json', 'r') as f: # Reads the list of most frequent words\n",
    "    important_words = json.load(f)\n",
    "important_words = [str(s) for s in important_words]\n",
    "len(important_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Let us perform 2 simple data transformations:\n",
    "\n",
    "- Remove punctuation\n",
    "- Compute word counts (only for important_words)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 53072 entries, 0 to 53071\n",
      "Data columns (total 4 columns):\n",
      "name         52982 non-null object\n",
      "review       53072 non-null object\n",
      "rating       53072 non-null float64\n",
      "sentiment    53072 non-null int64\n",
      "dtypes: float64(1), int64(1), object(2)\n",
      "memory usage: 1.6+ MB\n"
     ]
    }
   ],
   "source": [
    "products = products.fillna({'review': \"\"}) # fill in N/A's in the review column\n",
    "products.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def remove_punctuation(text):\n",
    "    import string\n",
    "    translator = str.maketrans(' ',' ', string.punctuation)\n",
    "    return text.translate(translator) \n",
    "\n",
    "products['review_clean'] = products['review'].apply(remove_punctuation)\n",
    "# products['review_clean'][1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Now we proceed with the second item. For each word in important_words, we compute a count for the number of times the word occurs in the review. We will store this count in a separate column (one for each word). The result of this feature processing is a single column for each word in important_words which keeps a count of the number of times the respective word occurs in the review text.\n",
    "\n",
    "Note: There are several ways of doing this. One way is to create an anonymous function that counts the occurrence of a particular word and apply it to every element in the review_clean column. Repeat this step for every word in important_words. Your code should be analogous to the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>review</th>\n",
       "      <th>rating</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>review_clean</th>\n",
       "      <th>baby</th>\n",
       "      <th>one</th>\n",
       "      <th>great</th>\n",
       "      <th>love</th>\n",
       "      <th>use</th>\n",
       "      <th>...</th>\n",
       "      <th>seems</th>\n",
       "      <th>picture</th>\n",
       "      <th>completely</th>\n",
       "      <th>wish</th>\n",
       "      <th>buying</th>\n",
       "      <th>babies</th>\n",
       "      <th>won</th>\n",
       "      <th>tub</th>\n",
       "      <th>almost</th>\n",
       "      <th>either</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Stop Pacifier Sucking without tears with Thumb...</td>\n",
       "      <td>All of my kids have cried non-stop when I trie...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "      <td>All of my kids have cried nonstop when I tried...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Nature's Lullabies Second Year Sticker Calendar</td>\n",
       "      <td>We wanted to get something to keep track of ou...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "      <td>We wanted to get something to keep track of ou...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Nature's Lullabies Second Year Sticker Calendar</td>\n",
       "      <td>My daughter had her 1st baby over a year ago. ...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "      <td>My daughter had her 1st baby over a year ago S...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Lamaze Peekaboo, I Love You</td>\n",
       "      <td>One of baby's first and favorite books, and it...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "      <td>One of babys first and favorite books and it i...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SoftPlay Peek-A-Boo Where's Elmo A Children's ...</td>\n",
       "      <td>Very cute interactive book! My son loves this ...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "      <td>Very cute interactive book My son loves this b...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 198 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                name  \\\n",
       "0  Stop Pacifier Sucking without tears with Thumb...   \n",
       "1    Nature's Lullabies Second Year Sticker Calendar   \n",
       "2    Nature's Lullabies Second Year Sticker Calendar   \n",
       "3                        Lamaze Peekaboo, I Love You   \n",
       "4  SoftPlay Peek-A-Boo Where's Elmo A Children's ...   \n",
       "\n",
       "                                              review  rating  sentiment  \\\n",
       "0  All of my kids have cried non-stop when I trie...     5.0          1   \n",
       "1  We wanted to get something to keep track of ou...     5.0          1   \n",
       "2  My daughter had her 1st baby over a year ago. ...     5.0          1   \n",
       "3  One of baby's first and favorite books, and it...     4.0          1   \n",
       "4  Very cute interactive book! My son loves this ...     5.0          1   \n",
       "\n",
       "                                        review_clean  baby  one  great  love  \\\n",
       "0  All of my kids have cried nonstop when I tried...     0    0      1     0   \n",
       "1  We wanted to get something to keep track of ou...     0    0      0     0   \n",
       "2  My daughter had her 1st baby over a year ago S...     1    0      0     0   \n",
       "3  One of babys first and favorite books and it i...     0    0      0     0   \n",
       "4  Very cute interactive book My son loves this b...     0    0      1     0   \n",
       "\n",
       "   use   ...    seems  picture  completely  wish  buying  babies  won  tub  \\\n",
       "0    0   ...        0        0           0     0       0       0    0    0   \n",
       "1    0   ...        0        0           0     0       0       0    0    0   \n",
       "2    0   ...        0        0           0     0       0       0    0    0   \n",
       "3    0   ...        0        0           0     0       0       0    0    0   \n",
       "4    0   ...        0        0           0     0       0       1    0    0   \n",
       "\n",
       "   almost  either  \n",
       "0       0       0  \n",
       "1       0       0  \n",
       "2       0       0  \n",
       "3       0       0  \n",
       "4       0       0  \n",
       "\n",
       "[5 rows x 198 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for word in important_words:\n",
    "    products[word] = products['review_clean'].apply(lambda s: s.split().count(word))\n",
    "    \n",
    "products.head()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-c18651ef3cce>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_json\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'module-4-assignment-train-idx.json'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mval_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_json\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'module-4-assignment-validation-idx.json'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mtrain_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_idx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mvalidation_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mval_idx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "train_idx = pd.read_json('module-4-assignment-train-idx.json')\n",
    "val_idx = pd.read_json('module-4-assignment-validation-idx.json')\n",
    "\n",
    "train_data = products.iloc[train_idx[0],:]\n",
    "validation_data = products.iloc[val_idx[0],:]\n",
    "train_data_copy = train_data.copy()\n",
    "val_data_copy = validation_data.copy()\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>review</th>\n",
       "      <th>rating</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>review_clean</th>\n",
       "      <th>baby</th>\n",
       "      <th>one</th>\n",
       "      <th>great</th>\n",
       "      <th>love</th>\n",
       "      <th>use</th>\n",
       "      <th>...</th>\n",
       "      <th>seems</th>\n",
       "      <th>picture</th>\n",
       "      <th>completely</th>\n",
       "      <th>wish</th>\n",
       "      <th>buying</th>\n",
       "      <th>babies</th>\n",
       "      <th>won</th>\n",
       "      <th>tub</th>\n",
       "      <th>almost</th>\n",
       "      <th>either</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Stop Pacifier Sucking without tears with Thumb...</td>\n",
       "      <td>All of my kids have cried non-stop when I trie...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "      <td>All of my kids have cried nonstop when I tried...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Nature's Lullabies Second Year Sticker Calendar</td>\n",
       "      <td>We wanted to get something to keep track of ou...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "      <td>We wanted to get something to keep track of ou...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Lamaze Peekaboo, I Love You</td>\n",
       "      <td>One of baby's first and favorite books, and it...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "      <td>One of babys first and favorite books and it i...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SoftPlay Peek-A-Boo Where's Elmo A Children's ...</td>\n",
       "      <td>Very cute interactive book! My son loves this ...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "      <td>Very cute interactive book My son loves this b...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Our Baby Girl Memory Book</td>\n",
       "      <td>Beautiful book, I love it to record cherished ...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "      <td>Beautiful book I love it to record cherished t...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 198 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                name  \\\n",
       "0  Stop Pacifier Sucking without tears with Thumb...   \n",
       "1    Nature's Lullabies Second Year Sticker Calendar   \n",
       "3                        Lamaze Peekaboo, I Love You   \n",
       "4  SoftPlay Peek-A-Boo Where's Elmo A Children's ...   \n",
       "5                          Our Baby Girl Memory Book   \n",
       "\n",
       "                                              review  rating  sentiment  \\\n",
       "0  All of my kids have cried non-stop when I trie...     5.0          1   \n",
       "1  We wanted to get something to keep track of ou...     5.0          1   \n",
       "3  One of baby's first and favorite books, and it...     4.0          1   \n",
       "4  Very cute interactive book! My son loves this ...     5.0          1   \n",
       "5  Beautiful book, I love it to record cherished ...     5.0          1   \n",
       "\n",
       "                                        review_clean  baby  one  great  love  \\\n",
       "0  All of my kids have cried nonstop when I tried...     0    0      1     0   \n",
       "1  We wanted to get something to keep track of ou...     0    0      0     0   \n",
       "3  One of babys first and favorite books and it i...     0    0      0     0   \n",
       "4  Very cute interactive book My son loves this b...     0    0      1     0   \n",
       "5  Beautiful book I love it to record cherished t...     0    0      1     1   \n",
       "\n",
       "   use   ...    seems  picture  completely  wish  buying  babies  won  tub  \\\n",
       "0    0   ...        0        0           0     0       0       0    0    0   \n",
       "1    0   ...        0        0           0     0       0       0    0    0   \n",
       "3    0   ...        0        0           0     0       0       0    0    0   \n",
       "4    0   ...        0        0           0     0       0       1    0    0   \n",
       "5    0   ...        0        0           0     0       0       0    0    0   \n",
       "\n",
       "   almost  either  \n",
       "0       0       0  \n",
       "1       0       0  \n",
       "3       0       0  \n",
       "4       0       0  \n",
       "5       0       0  \n",
       "\n",
       "[5 rows x 198 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>review</th>\n",
       "      <th>rating</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>review_clean</th>\n",
       "      <th>baby</th>\n",
       "      <th>one</th>\n",
       "      <th>great</th>\n",
       "      <th>love</th>\n",
       "      <th>use</th>\n",
       "      <th>...</th>\n",
       "      <th>seems</th>\n",
       "      <th>picture</th>\n",
       "      <th>completely</th>\n",
       "      <th>wish</th>\n",
       "      <th>buying</th>\n",
       "      <th>babies</th>\n",
       "      <th>won</th>\n",
       "      <th>tub</th>\n",
       "      <th>almost</th>\n",
       "      <th>either</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Nature's Lullabies Second Year Sticker Calendar</td>\n",
       "      <td>My daughter had her 1st baby over a year ago. ...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "      <td>My daughter had her 1st baby over a year ago S...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Cloth Diaper Pins Stainless Steel Traditional ...</td>\n",
       "      <td>It has been many years since we needed diaper ...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "      <td>It has been many years since we needed diaper ...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Fisher Price Nesting Action Vehicles</td>\n",
       "      <td>For well over a year my son has enjoyed stacki...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "      <td>For well over a year my son has enjoyed stacki...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Sassy Who Loves Baby? Photo Album Book with te...</td>\n",
       "      <td>I bought this for a new granddaughter.  I will...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "      <td>I bought this for a new granddaughter  I will ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Earlyears: Earl E. Bird with Teething Rings</td>\n",
       "      <td>We received an Earl E. Bird as a gift when we ...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "      <td>We received an Earl E Bird as a gift when we h...</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 198 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 name  \\\n",
       "2     Nature's Lullabies Second Year Sticker Calendar   \n",
       "9   Cloth Diaper Pins Stainless Steel Traditional ...   \n",
       "23               Fisher Price Nesting Action Vehicles   \n",
       "26  Sassy Who Loves Baby? Photo Album Book with te...   \n",
       "27        Earlyears: Earl E. Bird with Teething Rings   \n",
       "\n",
       "                                               review  rating  sentiment  \\\n",
       "2   My daughter had her 1st baby over a year ago. ...     5.0          1   \n",
       "9   It has been many years since we needed diaper ...     5.0          1   \n",
       "23  For well over a year my son has enjoyed stacki...     5.0          1   \n",
       "26  I bought this for a new granddaughter.  I will...     5.0          1   \n",
       "27  We received an Earl E. Bird as a gift when we ...     5.0          1   \n",
       "\n",
       "                                         review_clean  baby  one  great  love  \\\n",
       "2   My daughter had her 1st baby over a year ago S...     1    0      0     0   \n",
       "9   It has been many years since we needed diaper ...     0    1      0     0   \n",
       "23  For well over a year my son has enjoyed stacki...     0    1      0     0   \n",
       "26  I bought this for a new granddaughter  I will ...     0    0      2     0   \n",
       "27  We received an Earl E Bird as a gift when we h...     4    0      1     0   \n",
       "\n",
       "    use   ...    seems  picture  completely  wish  buying  babies  won  tub  \\\n",
       "2     0   ...        0        0           0     0       0       0    0    0   \n",
       "9     0   ...        0        0           0     0       0       0    0    0   \n",
       "23    0   ...        0        0           0     0       0       0    0    0   \n",
       "26    0   ...        0        0           0     0       0       0    0    0   \n",
       "27    0   ...        0        0           0     0       0       0    0    0   \n",
       "\n",
       "    almost  either  \n",
       "2        0       0  \n",
       "9        0       0  \n",
       "23       0       0  \n",
       "26       0       0  \n",
       "27       0       0  \n",
       "\n",
       "[5 rows x 198 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert data frame to multi-dimensional array\n",
    "\n",
    "Write a function that extracts columns from a data frame and converts them into a multi-dimensional array. We plan to use them throughout the course, so make sure to get this function right.\n",
    "\n",
    "#### The function should accept three parameters:\n",
    "- dataframe: a data frame to be converted\n",
    "- features: a list of string, containing the names of the columns that are used as features.\n",
    "- label: a string, containing the name of the single column that is used as class labels.\n",
    "\n",
    "#### The function should return two values:\n",
    "- one 2D array for features\n",
    "- one 1D array for class labels\n",
    "\n",
    "#### The function should do the following:\n",
    "- Prepend a new column constant to dataframe and fill it with 1's. This column takes account of the intercept term. - - Make sure that the constant column appears first in the data frame.\n",
    "- Prepend a string 'constant' to the list features. Make sure the string 'constant' appears first in the list.\n",
    "- Extract columns in dataframe whose names appear in the list features.\n",
    "- Convert the extracted columns into a 2D array using a function in the data frame library. If you are using Pandas, you would use as_matrix() function.\n",
    "- Extract the single column in dataframe whose name corresponds to the string label.\n",
    "- Convert the column into a 1D array.\n",
    "- Return the 2D array and the 1D array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_numpy_data(dataframe, features, label):\n",
    "    dataframe['constant'] = 1\n",
    "    features = ['constant'] + features\n",
    "    features_frame = dataframe[features]\n",
    "    feature_matrix = features_frame.as_matrix()\n",
    "    label_sarray = dataframe[label]\n",
    "    label_array = label_sarray.as_matrix()\n",
    "    return(feature_matrix, label_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Convert train_data and validation_data into multi-dimensional arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gcptien/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "feature_matrix_train, sentiment_train = get_numpy_data(train_data, important_words, 'sentiment')\n",
    "feature_matrix_valid, sentiment_valid = get_numpy_data(validation_data, important_words, 'sentiment') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feature_matrix, sentiment = get_numpy_data(products, important_words, 'sentiment')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(42361, 194)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_matrix_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Estimating conditional probability with link function\n",
    "$P(y_i = +1 | \\mathbf{x}_i, \\mathbf{w}) = \\dfrac{1}{1 + \\exp{(-\\mathbf{w}^\\intercal h(\\mathbf{x}_i))}}$\n",
    "\n",
    "where the feature vector $h(\\mathbf{x}_i)$ represents the word counts of important_words in the review $\\mathbf{x}_i$\n",
    "\n",
    "Write a function named predict_probability that implements the link function.\n",
    "\n",
    "Take two parameters: feature_matrix and coefficients.\n",
    "First compute the dot product of feature_matrix and coefficients.\n",
    "Then compute the link function $P(y = +1 | \\mathbf{x}, \\mathbf{w})$.\n",
    "Return the predictions given by the link function.\n",
    "Your code should be analogous to the following Python function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### '''\n",
    "### produces probablistic estimate for P(y_i = +1 | x_i, w).\n",
    "###estimate ranges between 0 and 1.\n",
    "###'''\n",
    "def predict_probability(feature_matrix, coefficients):\n",
    "    # Take dot product of feature_matrix and coefficients  \n",
    "    score = np.dot(feature_matrix, coefficients)\n",
    "    \n",
    "    # Compute P(y_i = +1 | x_i, w) using the link function\n",
    "    predictions = 1 / (1 + np.exp(-score))\n",
    "    \n",
    "    # return predictions\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The following outputs must match \n",
      "------------------------------------------------\n",
      "correct_predictions           = [ 0.98201379  0.26894142]\n",
      "output of predict_probability = [ 0.98201379  0.26894142]\n"
     ]
    }
   ],
   "source": [
    "dummy_feature_matrix = np.array([[1.,2.,3.], [1.,-1.,-1]])\n",
    "dummy_coefficients = np.array([1., 3., -1.])\n",
    "\n",
    "correct_scores      = np.array( [ 1.*1. + 2.*3. + 3.*(-1.),          1.*1. + (-1.)*3. + (-1.)*(-1.) ] )\n",
    "correct_predictions = np.array( [ 1./(1+np.exp(-correct_scores[0])), 1./(1+np.exp(-correct_scores[1])) ] )\n",
    "\n",
    "print ('The following outputs must match ')\n",
    "print ('------------------------------------------------')\n",
    "print ('correct_predictions           =', correct_predictions)\n",
    "print ('output of predict_probability =', predict_probability(dummy_feature_matrix, dummy_coefficients))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adding L2 penalty\n",
    "## 8. Let us now work on extending logistic regression with an L2 penalty. As discussed in the lectures, the L2 regularization is particularly useful in preventing overfitting. In this assignment, we will explore L2 regularization in detail.\n",
    "\n",
    "Recall from lecture and the previous assignment that for logistic regression without an L2 penalty, the derivative of the log-likelihood function is:\n",
    "\n",
    "$\\displaystyle \\frac{\\partial \\ell}{\\partial w_j} = \\sum_{i=1}^N h_j(\\mathbf{x}_i) (\\mathbf{1}[y_i = +1] - P(y_i = +1 | \\mathbf{x}_i, \\mathbf{w})) $\n",
    "\n",
    "\n",
    "Adding L2 penalty to the derivative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def feature_derivative_with_L2(errors, feature, coefficient, l2_penalty, feature_is_constant): \n",
    "    \n",
    "    # Compute the dot product of errors and feature\n",
    "    ## YOUR CODE HERE\n",
    "    derivative = np.dot(errors,feature)\n",
    "\n",
    "    # add L2 penalty term for any feature that isn't the intercept.\n",
    "    if not feature_is_constant: \n",
    "        derivative = derivative - (2 * l2_penalty * coefficient)\n",
    "        \n",
    "    return derivative"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quiz question: In the code above, was the intercept term regularized?\n",
    "NO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adding L2 penalty to the derivative\n",
    "\n",
    "## 9. It takes only a small modification to add a L2 penalty. All terms indicated in red refer to terms that were added due to an L2 penalty.\n",
    "\n",
    "Recall from the lecture that the link function is still the sigmoid:\n",
    "$P(y_i = +1 | \\mathbf{x}_i, \\mathbf{w}) = \\dfrac{1}{1 + \\exp{(-\\mathbf{w}^\\intercal h(\\mathbf{x}_i))}}$\n",
    "\n",
    "We add the L2 penalty term to the per-coefficient derivative of log likelihood:\n",
    "$\\displaystyle \\frac{\\partial \\ell}{\\partial w_j} = \\sum_{i=1}^N h_j(\\mathbf{x}_i) (\\mathbf{1}[y_i = +1] - P(y_i = +1 | \\mathbf{x}_i, \\mathbf{w})) \\color{red}{- 2\\lambda w_j} $\n",
    "\n",
    "The per-coefficient derivative for logistic regression with an L2 penalty is as follows:\n",
    "\n",
    "$\\displaystyle \\frac{\\partial \\ell}{\\partial w_j} = \\sum_{i=1}^N h_j(\\mathbf{x}_i) (\\mathbf{1}[y_i = +1] - P(y_i = +1 | \\mathbf{x}_i, \\mathbf{w})) \\color{red}{- 2\\lambda w_j} $\n",
    "\n",
    "and for the intercept term, we have\n",
    "\n",
    "$\\displaystyle \\frac{\\partial \\ell}{\\partial w_0} = \\sum_{i=1}^N h_0(\\mathbf{x}_i) (\\mathbf{1}[y_i = +1] - P(y_i = +1 | \\mathbf{x}_i, \\mathbf{w})) $\n",
    "\n",
    "Write a function that computes the derivative of log likelihood with respect to a single coefficient w_j. Unlike its counterpart in the last assignment, the function accepts five parameters:\n",
    "\n",
    "- errors: vector whose i-th value contains\n",
    "$\\mathbf{1}[y_i = +1] - P(y_i = +1 | \\mathbf{x}_i, \\mathbf{w})$\n",
    "\n",
    "- feature: vector whose i-th value contains\n",
    "$h_j(\\mathbf{x}_i)$\n",
    "- coefficient: the current value of the j-th coefficient.\n",
    "- l2_penalty: the L2 penalty constant \\lambdaλ\n",
    "- feature_is_constant: a Boolean value indicating whether the j-th feature is constant or not.\n",
    "\n",
    "The function should do the following:\n",
    "\n",
    "- Take the five parameters as above.\n",
    "- Compute the dot product of errors and feature and save the result to derivative.\n",
    "- If feature_is_constant is False, subtract the L2 penalty term from derivative. Otherwise, do nothing.\n",
    "Return derivative."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. To verify the correctness of the gradient descent algorithm, we write a function for computing log likelihood (which we recall from the last assignment was a topic detailed in an advanced optional video, and used here for its numerical stability), which is given by the formula\n",
    "\n",
    "$\\displaystyle \\ell \\ell (\\mathbf{w}) = \\sum_{i=1}^N \\Big( (\\mathbf{1}[y_i = +1] - 1) \\mathbf{w}^\\intercal h(\\mathbf{w}_i) - \\ln{\\big(1 + \\exp{(-\\mathbf{w}^\\intercal h(\\mathbf{x}_i) )} \\big)} \\Big) \\color{red}{-\\lambda \\|\\mathbf{w}\\|_2^2}$\n",
    "\n",
    "The function should be analogous to the following Python function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compute_log_likelihood_with_L2(feature_matrix, sentiment, coefficients, l2_penalty):\n",
    "    indicator = (sentiment==+1)\n",
    "    scores = np.dot(feature_matrix, coefficients)\n",
    "    \n",
    "    lp = np.sum((indicator-1)*scores - np.log(1. + np.exp(-scores))) - l2_penalty*np.sum(coefficients[1:]**2)\n",
    "    \n",
    "    return lp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quiz question: Does the term with L2 regularization increase or decrease ℓℓ(w)?\n",
    "\n",
    "Decrease"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# 11. The logistic regression function looks almost like the one in the last assignment, with a minor modification to account for the L2 penalty.\n",
    "\n",
    "Write a function logistic_regression_with_L2 to fit a logistic regression model under L2 regularization.\n",
    "\n",
    "The function accepts the following parameters:\n",
    "\n",
    "- feature_matrix: 2D array of features\n",
    "- sentiment: 1D array of class labels\n",
    "- initial_coefficients: 1D array containing initial values of coefficients\n",
    "- step_size: a parameter controlling the size of the gradient steps\n",
    "- l2_penalty: the L2 penalty constant $\\lambda$\n",
    "- max_iter: number of iterations to run gradient ascent\n",
    "\n",
    "The function returns the last set of coefficients after performing gradient ascent.\n",
    "\n",
    "The function carries out the following steps:\n",
    "\n",
    "- Initialize vector coefficients to initial_coefficients.\n",
    "- Predict the class probability $P(y_i = +1 | \\mathbf{x}_i,\\mathbf{w})$\n",
    "using your predict_probability function and save it to variable predictions.\n",
    "- Compute indicator value for $(y_i = +1)$ by comparing sentiment against +1. \n",
    "- Save it to variable indicator.\n",
    "- Compute the errors as difference between indicator and predictions. Save the errors to variable errors.\n",
    "- For each j-th coefficient, compute the per-coefficient derivative by calling feature_derivative_L2 with the j-th column of feature_matrix. Don't forget to supply the L2 penalty. Then increment the j-th coefficient by (step_size*derivative).\n",
    "- Once in a while, insert code to print out the log likelihood.\n",
    "- Repeat steps 2-6 for max_iter times.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def logistic_regression_with_L2(feature_matrix, sentiment, initial_coefficients, step_size, l2_penalty, max_iter):\n",
    "    coefficients = np.array(initial_coefficients) # make sure it's a numpy array\n",
    "    for itr in range(max_iter):\n",
    "        # Predict P(y_i = +1|x_i,w) using your predict_probability() function\n",
    "        ## YOUR CODE HERE\n",
    "        predictions = predict_probability(feature_matrix,coefficients)\n",
    "        \n",
    "        # Compute indicator value for (y_i = +1)\n",
    "        indicator = (sentiment==+1)\n",
    "        \n",
    "        # Compute the errors as indicator - predictions\n",
    "        errors = indicator - predictions\n",
    "        for j in range(len(coefficients)): # loop over each coefficient\n",
    "            is_intercept = (j == 0)\n",
    "            # Recall that feature_matrix[:,j] is the feature column associated with coefficients[j].\n",
    "            # Compute the derivative for coefficients[j]. Save it in a variable called derivative\n",
    "            ## YOUR CODE HERE\n",
    "            derivative = feature_derivative_with_L2(errors, feature_matrix[:,j], coefficients[j], l2_penalty, is_intercept)\n",
    "            \n",
    "            # add the step size times the derivative to the current coefficient\n",
    "            ## YOUR CODE HERE\n",
    "            coefficients[j] += step_size * derivative\n",
    "        \n",
    "        # Checking whether log likelihood is increasing\n",
    "        if itr <= 15 or (itr <= 100 and itr % 10 == 0) or (itr <= 1000 and itr % 100 == 0) \\\n",
    "        or (itr <= 10000 and itr % 1000 == 0) or itr % 10000 == 0:\n",
    "            lp = compute_log_likelihood_with_L2(feature_matrix, sentiment, coefficients, l2_penalty)\n",
    "            print ('iteration %*d: log likelihood of observed labels = %.8f' % \\\n",
    "                (int(np.ceil(np.log10(max_iter))), itr, lp))\n",
    "    return coefficients"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Now that we have written up all the pieces needed for an L2 solver with logistic regression, let's explore the benefits of using L2 regularization while analyzing sentiment for product reviews. As iterations pass, the log likelihood should increase.\n",
    "\n",
    "Let us train models with increasing amounts of regularization, starting with no L2 penalty, which is equivalent to our previous logistic regression implementation. Train 6 models with L2 penalty values 0, 4, 10, 1e2, 1e3, and 1e5. Use the following values for the other parameters:\n",
    "\n",
    "- feature_matrix = feature_matrix_train extracted in #7\n",
    "- sentiment = sentiment_train extracted in #7\n",
    "- initial_coefficients = a 194-dimensional vector filled with zeros\n",
    "- step_size = 5e-6\n",
    "- max_iter = 501\n",
    "- Save the 6 sets of coefficients as coefficients_0_penalty, coefficients_4_penalty, coefficients_10_penalty, coefficients_1e2_penalty, coefficients_1e3_penalty, and coefficients_1e5_penalty respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration   0: log likelihood of observed labels = -29179.39138303\n",
      "iteration   1: log likelihood of observed labels = -29003.71259047\n",
      "iteration   2: log likelihood of observed labels = -28834.66187288\n",
      "iteration   3: log likelihood of observed labels = -28671.70781507\n",
      "iteration   4: log likelihood of observed labels = -28514.43078198\n",
      "iteration   5: log likelihood of observed labels = -28362.48344665\n",
      "iteration   6: log likelihood of observed labels = -28215.56713122\n",
      "iteration   7: log likelihood of observed labels = -28073.41743783\n",
      "iteration   8: log likelihood of observed labels = -27935.79536396\n",
      "iteration   9: log likelihood of observed labels = -27802.48168669\n",
      "iteration  10: log likelihood of observed labels = -27673.27331484\n",
      "iteration  11: log likelihood of observed labels = -27547.98083656\n",
      "iteration  12: log likelihood of observed labels = -27426.42679977\n",
      "iteration  13: log likelihood of observed labels = -27308.44444728\n",
      "iteration  14: log likelihood of observed labels = -27193.87673876\n",
      "iteration  15: log likelihood of observed labels = -27082.57555831\n",
      "iteration  20: log likelihood of observed labels = -26570.43059938\n",
      "iteration  30: log likelihood of observed labels = -25725.48742389\n",
      "iteration  40: log likelihood of observed labels = -25055.53326910\n",
      "iteration  50: log likelihood of observed labels = -24509.63590026\n",
      "iteration  60: log likelihood of observed labels = -24054.97906083\n",
      "iteration  70: log likelihood of observed labels = -23669.51640848\n",
      "iteration  80: log likelihood of observed labels = -23337.89167628\n",
      "iteration  90: log likelihood of observed labels = -23049.07066021\n",
      "iteration 100: log likelihood of observed labels = -22794.90974921\n",
      "iteration 200: log likelihood of observed labels = -21283.29527353\n",
      "iteration 300: log likelihood of observed labels = -20570.97485473\n",
      "iteration 400: log likelihood of observed labels = -20152.21466944\n",
      "iteration 500: log likelihood of observed labels = -19876.62333410\n"
     ]
    }
   ],
   "source": [
    "coefficients_0_penalty = logistic_regression_with_L2(feature_matrix_train, sentiment_train,\n",
    "                                                     initial_coefficients=np.zeros(194),\n",
    "                                                     step_size=5e-6, l2_penalty=0, max_iter=501)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration   0: log likelihood of observed labels = -29179.40062984\n",
      "iteration   1: log likelihood of observed labels = -29003.76654163\n",
      "iteration   2: log likelihood of observed labels = -28834.79322654\n",
      "iteration   3: log likelihood of observed labels = -28671.94687528\n",
      "iteration   4: log likelihood of observed labels = -28514.80571589\n",
      "iteration   5: log likelihood of observed labels = -28363.02048079\n",
      "iteration   6: log likelihood of observed labels = -28216.29071186\n",
      "iteration   7: log likelihood of observed labels = -28074.35036891\n",
      "iteration   8: log likelihood of observed labels = -27936.95892966\n",
      "iteration   9: log likelihood of observed labels = -27803.89576265\n",
      "iteration  10: log likelihood of observed labels = -27674.95647005\n",
      "iteration  11: log likelihood of observed labels = -27549.95042714\n",
      "iteration  12: log likelihood of observed labels = -27428.69905549\n",
      "iteration  13: log likelihood of observed labels = -27311.03455140\n",
      "iteration  14: log likelihood of observed labels = -27196.79890162\n",
      "iteration  15: log likelihood of observed labels = -27085.84308528\n",
      "iteration  20: log likelihood of observed labels = -26575.59697506\n",
      "iteration  30: log likelihood of observed labels = -25735.07304608\n",
      "iteration  40: log likelihood of observed labels = -25070.03447306\n",
      "iteration  50: log likelihood of observed labels = -24529.31188025\n",
      "iteration  60: log likelihood of observed labels = -24079.95349572\n",
      "iteration  70: log likelihood of observed labels = -23699.83199186\n",
      "iteration  80: log likelihood of observed labels = -23373.54108747\n",
      "iteration  90: log likelihood of observed labels = -23090.01500055\n",
      "iteration 100: log likelihood of observed labels = -22841.08995135\n",
      "iteration 200: log likelihood of observed labels = -21377.25595328\n",
      "iteration 300: log likelihood of observed labels = -20704.63995428\n",
      "iteration 400: log likelihood of observed labels = -20319.25685307\n",
      "iteration 500: log likelihood of observed labels = -20072.16321721\n"
     ]
    }
   ],
   "source": [
    "coefficients_10_penalty = logistic_regression_with_L2(feature_matrix_train, sentiment_train,\n",
    "                                                      initial_coefficients=np.zeros(194),\n",
    "                                                      step_size=5e-6, l2_penalty=10, max_iter=501)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration   0: log likelihood of observed labels = -29179.39508175\n",
      "iteration   1: log likelihood of observed labels = -29003.73417180\n",
      "iteration   2: log likelihood of observed labels = -28834.71441858\n",
      "iteration   3: log likelihood of observed labels = -28671.80345068\n",
      "iteration   4: log likelihood of observed labels = -28514.58077957\n",
      "iteration   5: log likelihood of observed labels = -28362.69830317\n",
      "iteration   6: log likelihood of observed labels = -28215.85663259\n",
      "iteration   7: log likelihood of observed labels = -28073.79071393\n",
      "iteration   8: log likelihood of observed labels = -27936.26093762\n",
      "iteration   9: log likelihood of observed labels = -27803.04751805\n",
      "iteration  10: log likelihood of observed labels = -27673.94684207\n",
      "iteration  11: log likelihood of observed labels = -27548.76901327\n",
      "iteration  12: log likelihood of observed labels = -27427.33612958\n",
      "iteration  13: log likelihood of observed labels = -27309.48101569\n",
      "iteration  14: log likelihood of observed labels = -27195.04624253\n",
      "iteration  15: log likelihood of observed labels = -27083.88333261\n",
      "iteration  20: log likelihood of observed labels = -26572.49874392\n",
      "iteration  30: log likelihood of observed labels = -25729.32604153\n",
      "iteration  40: log likelihood of observed labels = -25061.34245801\n",
      "iteration  50: log likelihood of observed labels = -24517.52091982\n",
      "iteration  60: log likelihood of observed labels = -24064.99093939\n",
      "iteration  70: log likelihood of observed labels = -23681.67373669\n",
      "iteration  80: log likelihood of observed labels = -23352.19298741\n",
      "iteration  90: log likelihood of observed labels = -23065.50180166\n",
      "iteration 100: log likelihood of observed labels = -22813.44844580\n",
      "iteration 200: log likelihood of observed labels = -21321.14164794\n",
      "iteration 300: log likelihood of observed labels = -20624.98634439\n",
      "iteration 400: log likelihood of observed labels = -20219.92048845\n",
      "iteration 500: log likelihood of observed labels = -19956.11341777\n"
     ]
    }
   ],
   "source": [
    "coefficients_4_penalty = logistic_regression_with_L2(feature_matrix_train, sentiment_train,\n",
    "                                                      initial_coefficients=np.zeros(194),\n",
    "                                                      step_size=5e-6, l2_penalty=4, max_iter=501)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration   0: log likelihood of observed labels = -29179.48385120\n",
      "iteration   1: log likelihood of observed labels = -29004.25177457\n",
      "iteration   2: log likelihood of observed labels = -28835.97382190\n",
      "iteration   3: log likelihood of observed labels = -28674.09410083\n",
      "iteration   4: log likelihood of observed labels = -28518.17112932\n",
      "iteration   5: log likelihood of observed labels = -28367.83774654\n",
      "iteration   6: log likelihood of observed labels = -28222.77708939\n",
      "iteration   7: log likelihood of observed labels = -28082.70799392\n",
      "iteration   8: log likelihood of observed labels = -27947.37595368\n",
      "iteration   9: log likelihood of observed labels = -27816.54738615\n",
      "iteration  10: log likelihood of observed labels = -27690.00588850\n",
      "iteration  11: log likelihood of observed labels = -27567.54970126\n",
      "iteration  12: log likelihood of observed labels = -27448.98991327\n",
      "iteration  13: log likelihood of observed labels = -27334.14912742\n",
      "iteration  14: log likelihood of observed labels = -27222.86041863\n",
      "iteration  15: log likelihood of observed labels = -27114.96648229\n",
      "iteration  20: log likelihood of observed labels = -26621.50201299\n",
      "iteration  30: log likelihood of observed labels = -25819.72803950\n",
      "iteration  40: log likelihood of observed labels = -25197.34035501\n",
      "iteration  50: log likelihood of observed labels = -24701.03698195\n",
      "iteration  60: log likelihood of observed labels = -24296.66378580\n",
      "iteration  70: log likelihood of observed labels = -23961.38842316\n",
      "iteration  80: log likelihood of observed labels = -23679.38088853\n",
      "iteration  90: log likelihood of observed labels = -23439.31824267\n",
      "iteration 100: log likelihood of observed labels = -23232.88192018\n",
      "iteration 200: log likelihood of observed labels = -22133.50726528\n",
      "iteration 300: log likelihood of observed labels = -21730.03957488\n",
      "iteration 400: log likelihood of observed labels = -21545.87572145\n",
      "iteration 500: log likelihood of observed labels = -21451.95551390\n"
     ]
    }
   ],
   "source": [
    "coefficients_1e2_penalty = logistic_regression_with_L2(feature_matrix_train, sentiment_train,\n",
    "                                                       initial_coefficients=np.zeros(194),\n",
    "                                                       step_size=5e-6, l2_penalty=1e2, max_iter=501)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration   0: log likelihood of observed labels = -29180.31606471\n",
      "iteration   1: log likelihood of observed labels = -29009.07176112\n",
      "iteration   2: log likelihood of observed labels = -28847.62378912\n",
      "iteration   3: log likelihood of observed labels = -28695.14439397\n",
      "iteration   4: log likelihood of observed labels = -28550.95060743\n",
      "iteration   5: log likelihood of observed labels = -28414.45771129\n",
      "iteration   6: log likelihood of observed labels = -28285.15124375\n",
      "iteration   7: log likelihood of observed labels = -28162.56976044\n",
      "iteration   8: log likelihood of observed labels = -28046.29387744\n",
      "iteration   9: log likelihood of observed labels = -27935.93902900\n",
      "iteration  10: log likelihood of observed labels = -27831.15045502\n",
      "iteration  11: log likelihood of observed labels = -27731.59955260\n",
      "iteration  12: log likelihood of observed labels = -27636.98108219\n",
      "iteration  13: log likelihood of observed labels = -27547.01092670\n",
      "iteration  14: log likelihood of observed labels = -27461.42422295\n",
      "iteration  15: log likelihood of observed labels = -27379.97375625\n",
      "iteration  20: log likelihood of observed labels = -27027.18208317\n",
      "iteration  30: log likelihood of observed labels = -26527.22737267\n",
      "iteration  40: log likelihood of observed labels = -26206.59048765\n",
      "iteration  50: log likelihood of observed labels = -25995.96903148\n",
      "iteration  60: log likelihood of observed labels = -25854.95710284\n",
      "iteration  70: log likelihood of observed labels = -25759.08109950\n",
      "iteration  80: log likelihood of observed labels = -25693.05688014\n",
      "iteration  90: log likelihood of observed labels = -25647.09929349\n",
      "iteration 100: log likelihood of observed labels = -25614.81468705\n",
      "iteration 200: log likelihood of observed labels = -25536.20998919\n",
      "iteration 300: log likelihood of observed labels = -25532.57691220\n",
      "iteration 400: log likelihood of observed labels = -25532.35543765\n",
      "iteration 500: log likelihood of observed labels = -25532.33970049\n"
     ]
    }
   ],
   "source": [
    "coefficients_1e3_penalty = logistic_regression_with_L2(feature_matrix_train, sentiment_train,\n",
    "                                                       initial_coefficients=np.zeros(194),\n",
    "                                                       step_size=5e-6, l2_penalty=1e3, max_iter=501)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration   0: log likelihood of observed labels = -29271.85955115\n",
      "iteration   1: log likelihood of observed labels = -29271.71006589\n",
      "iteration   2: log likelihood of observed labels = -29271.65738833\n",
      "iteration   3: log likelihood of observed labels = -29271.61189923\n",
      "iteration   4: log likelihood of observed labels = -29271.57079975\n",
      "iteration   5: log likelihood of observed labels = -29271.53358505\n",
      "iteration   6: log likelihood of observed labels = -29271.49988440\n",
      "iteration   7: log likelihood of observed labels = -29271.46936584\n",
      "iteration   8: log likelihood of observed labels = -29271.44172890\n",
      "iteration   9: log likelihood of observed labels = -29271.41670149\n",
      "iteration  10: log likelihood of observed labels = -29271.39403722\n",
      "iteration  11: log likelihood of observed labels = -29271.37351294\n",
      "iteration  12: log likelihood of observed labels = -29271.35492661\n",
      "iteration  13: log likelihood of observed labels = -29271.33809523\n",
      "iteration  14: log likelihood of observed labels = -29271.32285309\n",
      "iteration  15: log likelihood of observed labels = -29271.30905015\n",
      "iteration  20: log likelihood of observed labels = -29271.25729150\n",
      "iteration  30: log likelihood of observed labels = -29271.20657205\n",
      "iteration  40: log likelihood of observed labels = -29271.18775997\n",
      "iteration  50: log likelihood of observed labels = -29271.18078247\n",
      "iteration  60: log likelihood of observed labels = -29271.17819447\n",
      "iteration  70: log likelihood of observed labels = -29271.17723457\n",
      "iteration  80: log likelihood of observed labels = -29271.17687853\n",
      "iteration  90: log likelihood of observed labels = -29271.17674648\n",
      "iteration 100: log likelihood of observed labels = -29271.17669750\n",
      "iteration 200: log likelihood of observed labels = -29271.17666862\n",
      "iteration 300: log likelihood of observed labels = -29271.17666862\n",
      "iteration 400: log likelihood of observed labels = -29271.17666862\n",
      "iteration 500: log likelihood of observed labels = -29271.17666862\n"
     ]
    }
   ],
   "source": [
    "coefficients_1e5_penalty = logistic_regression_with_L2(feature_matrix_train, sentiment_train,\n",
    "                                                       initial_coefficients=np.zeros(194),\n",
    "                                                       step_size=5e-6, l2_penalty=1e5, max_iter=501)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare coefficients\n",
    "## 13. We now compare the coefficients for each of the models that were trained above. Create a table of features and learned coefficients associated with each of the different L2 penalty values.\n",
    "\n",
    "Using the coefficients trained with L2 penalty 0, find the 5 most positive words (with largest positive coefficients). Save them to positive_words. Similarly, find the 5 most negative words (with largest negative coefficients) and save them to negative_words.\n",
    "\n",
    "### Quiz Question. Which of the following is not listed in either positive_words or negative_words?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive Words\n",
      "         coefficients_0_penalty\n",
      "love                   1.058554\n",
      "loves                  1.052484\n",
      "easy                   0.984559\n",
      "perfect                0.835693\n",
      "great                  0.801625\n",
      "\n",
      "Negative Words\n",
      "              coefficients_0_penalty\n",
      "disappointed               -0.955437\n",
      "money                      -0.768793\n",
      "return                     -0.742085\n",
      "waste                      -0.617809\n",
      "returned                   -0.572707\n"
     ]
    }
   ],
   "source": [
    "df_0 = pd.DataFrame(coefficients_0_penalty, index= index, columns=['coefficients_0_penalty'])\n",
    "df = df_0.copy()\n",
    "# df_0 = df_0.reset_index()\n",
    "#df_0.sort_values(by='word', ascending = False)\n",
    "df_0.sort_values(by='coefficients_0_penalty')\n",
    "print('Positive Words')\n",
    "print(df_0.sort_values(by='coefficients_0_penalty',ascending=False).head())\n",
    "print()\n",
    "print('Negative Words')\n",
    "print(df_0.sort_values(by='coefficients_0_penalty',ascending=True).head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['disappointed', 'money', 'return', 'waste', 'returned']"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "positive = df_0.sort_values(by='coefficients_0_penalty',ascending=False).index[0:5].tolist()\n",
    "negative = df_0.sort_values(by='coefficients_0_penalty',ascending=True).index[0:5].tolist()\n",
    "positive\n",
    "negative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['coefficients_4_penalty'] = coefficients_4_penalty\n",
    "df['coefficients_10_penalty'] = coefficients_10_penalty\n",
    "df['coefficients_1e2_penalty'] = coefficients_1e2_penalty\n",
    "df['coefficients_1e3_penalty'] = coefficients_1e3_penalty\n",
    "df['coefficients_1e5_penalty'] = coefficients_1e5_penalty\n",
    "df.head()\n",
    "test = df.copy()\n",
    "pos_word = test.loc[positive]\n",
    "neg_word = test.loc[negative]\n",
    "df = df.reset_index()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 14. Let us observe the effect of increasing L2 penalty on the 10 words just selected. Make a plot of the coefficients for the 10 words over the different values of L2 penalty.\n",
    "\n",
    "Hints:\n",
    "\n",
    "- First, extract rows corresponding to positive_words. Do the same for negative_words.\n",
    "- Then plot each of the extracted rows. The x axis should be L2 penalty and the y axis should be the coefficient value.\n",
    "- Use log scale for the x axis, as the L2 penalty values are exponentially spaced."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAArcAAAGXCAYAAACp2XjcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nlsdTrHgAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10a33b4a8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = 10, 6\n",
    "\n",
    "def make_coefficient_plot(table, positive_words, negative_words, l2_penalty_list):\n",
    "    cmap_positive = plt.get_cmap('Reds')\n",
    "    cmap_negative = plt.get_cmap('Blues')\n",
    "    \n",
    "    xx = l2_penalty_list\n",
    "    plt.plot(xx, [0.]*len(xx), '--', lw=1, color='k')\n",
    "    \n",
    "    table_positive_words = table[table['index'].isin(positive_words)]\n",
    "    table_negative_words = table[table['index'].isin(negative_words)]\n",
    "    del table_positive_words['index']\n",
    "    del table_negative_words['index']\n",
    "    \n",
    "    for i in range(len(positive_words)):\n",
    "        color = cmap_positive(0.8*((i+1)/(len(positive_words)*1.2)+0.15))\n",
    "        plt.plot(xx, table_positive_words[i:i+1].as_matrix().flatten(),\n",
    "                 '-', label=positive_words[i], linewidth=4.0, color=color)\n",
    "        \n",
    "    for i in range(len(negative_words)):\n",
    "        color = cmap_negative(0.8*((i+1)/(len(negative_words)*1.2)+0.15))\n",
    "        plt.plot(xx, table_negative_words[i:i+1].as_matrix().flatten(),\n",
    "                 '-', label=negative_words[i], linewidth=4.0, color=color)\n",
    "        \n",
    "    plt.legend(loc='best', ncol=3, prop={'size':16}, columnspacing=0.5)\n",
    "    plt.axis([1, 1e5, -1, 2])\n",
    "    plt.title('Coefficient path')\n",
    "    plt.xlabel('L2 penalty ($\\lambda$)')\n",
    "    plt.ylabel('Coefficient value')\n",
    "    plt.xscale('log')\n",
    "    plt.rcParams.update({'font.size': 18})\n",
    "    plt.tight_layout()\n",
    "\n",
    "\n",
    "make_coefficient_plot(df, positive, negative, l2_penalty_list=[0, 4, 10, 1e2, 1e3, 1e5])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quiz Question: (True/False) All coefficients consistently get smaller in size as L2 penalty is increased.\n",
    "   <h4><font color =red>True</font></h4>\n",
    "\n",
    "### Quiz Question: (True/False)) Relative order of coefficients is preserved as L2 penalty is increased. (If word 'cat' was more positive than word 'dog', then it remains to be so as L2 penalty is increased.)\n",
    "   <h4><font color =red>False</font></h4>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Measuring accuracy\n",
    "## 15. Now, let us compute the accuracy of the classifier model. Recall that the accuracy is given by\n",
    "\n",
    "accuracy=# correctly classified data points# total data points\n",
    "Recall from lecture that that the class prediction is calculated using\n",
    "\n",
    "Note: It is important to know that the model prediction code doesn't change even with L2 penalty. The only thing that changes is that the estimated coefficients used in this prediction are different with L2 penalty.\n",
    "\n",
    "### Quiz question: Which model (L2 = 0, 4, 10, 100, 1e3, 1e5) has the highest accuracy on the training data?\n",
    "### Quiz question: Which model (L2 = 0, 4, 10, 100, 1e3, 1e5) has the highest accuracy on the validation data?\n",
    "### Quiz question: Does the highest accuracy on the training data imply that the model is the best one?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_accuracy(feature_matrix, sentiment, coefficients):\n",
    "    scores = np.dot(feature_matrix,coefficients)\n",
    "    pred_fuc = np.vectorize(lambda x: 1 if x> 0 else -1)\n",
    "    class_prediction = pred_fuc(scores)\n",
    "    \n",
    "    num_correct = (class_prediction == sentiment).sum()\n",
    "    accuracy = num_correct / len(feature_matrix)    \n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_accuracy = {}\n",
    "valid_accuracy = {}\n",
    "train_accuracy[0] = get_accuracy(feature_matrix_train,sentiment_train,coefficients_0_penalty)\n",
    "train_accuracy[4] = get_accuracy(feature_matrix_train,sentiment_train,coefficients_4_penalty)\n",
    "train_accuracy[10] = get_accuracy(feature_matrix_train,sentiment_train,coefficients_10_penalty)\n",
    "train_accuracy[100] = get_accuracy(feature_matrix_train,sentiment_train,coefficients_1e2_penalty)\n",
    "train_accuracy[1e3] = get_accuracy(feature_matrix_train,sentiment_train,coefficients_1e3_penalty)\n",
    "train_accuracy[1e5] = get_accuracy(feature_matrix_train,sentiment_train,coefficients_1e5_penalty)\n",
    "valid_accuracy[0] = get_accuracy(feature_matrix_valid,sentiment_valid,coefficients_0_penalty)\n",
    "valid_accuracy[4] = get_accuracy(feature_matrix_valid,sentiment_valid,coefficients_4_penalty)\n",
    "valid_accuracy[10] = get_accuracy(feature_matrix_valid,sentiment_valid,coefficients_10_penalty)\n",
    "valid_accuracy[100] = get_accuracy(feature_matrix_valid,sentiment_valid,coefficients_1e2_penalty)\n",
    "valid_accuracy[1e3] = get_accuracy(feature_matrix_valid,sentiment_valid,coefficients_1e3_penalty)\n",
    "valid_accuracy[1e5] = get_accuracy(feature_matrix_valid,sentiment_valid,coefficients_1e5_penalty)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({0: 0.78515615778664338,\n",
       "  4: 0.78510894454805125,\n",
       "  10: 0.78499091145157107,\n",
       "  100: 0.78397582682184086,\n",
       "  1000.0: 0.77585514978399939,\n",
       "  100000.0: 0.68036637473147465},\n",
       " {0: 0.78143964149005696,\n",
       "  4: 0.78153300345439269,\n",
       "  10: 0.78171972738306417,\n",
       "  100: 0.78106619363271401,\n",
       "  1000.0: 0.7713565493417982,\n",
       "  100000.0: 0.66781813089347397})"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_accuracy, valid_accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sentiment"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
